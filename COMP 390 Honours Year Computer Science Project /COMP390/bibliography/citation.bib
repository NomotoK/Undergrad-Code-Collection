@article{OMR_def,
  author = {Nutchanat Sattayakawee},
  title = {Test Scoring for Non-Optical Grid Answer Sheet Based on Projection Profile Method},
  journal = {International Journal of Information and Education Technology},
  year = {2013},
  volume = {2},
  pages = {2-3}
}

@misc{OMR_wiki,
  author = {Wikipedia},
  year = {2020},
  title = {Optical mark recognition},
  url = {https://en.wikipedia.org/wiki/Optical_mark_recognition},
  urldate = {March 9, 2017}
}

@Inbook{OCR_1,
author="R. Seetharaman",
editor= "James Carol",
title="Optical Character Recognition using Convolutional Neural Network",
bookTitle="Optical Character Recognition using Convolutional Neural Network",
year="2022",
publisher="CRC Press",
address="Cham",
pages="485--520",
isbn="9781003216742",
doi="10.1007/978-3-030-72116-9_18",
url="https://doi.org/10.1007/978-3-030-72116-9_18"
}

@misc{CV_1,
  author = {Adrian Rosebrock},
  year = {2016},
  title = {Bubble sheet multiple choice scanner and test grader using OMR, Python, and OpenCV},
  url = {https://pyimagesearch.com/2016/10/03/},
  urldate = {March 9, 2017}
}

@misc{opencv,
  author = {OpenCV},
  year = {2023},
  title = {OpenCV official website},
  url = {https://opencv.org/},
  urldate = {Nov 9, 2023}
}

@INPROCEEDINGS{OTSU,
  author={Qu, Zhong and Zhang, Li},
  booktitle={2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics}, 
  title={Research on Image Segmentation Based on the Improved Otsu Algorithm}, 
  year={2010},
  volume={2},
  number={},
  pages={228-231},
  doi={10.1109/IHMSC.2010.157}}

@misc{canny,
  author = {OpenCV},
  year = {2023},
  title = {Canny Edge Detection},
  url = {https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html},
  urldate = {Nov 9, 2023}
}

@misc{canny_wiki,
  author = {Wikipedia},
  year = {2023},
  title = {Canny edge detector},
  url = {https://en.wikipedia.org/wiki/Canny_edge_detector},
  urldate = {Nov 1, 2023}
}

@INPROCEEDINGS{OMR_ieee1,
  author={Jain, Viraj and Malik, Siddharth and Bhatia, Vimal},
  booktitle={2022 IEEE 6th Conference on Information and Communication Technology (CICT)}, 
  title={Robust Image Processing based Real-time Optical Mark Recognition System}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/CICT56698.2022.9997878}}

@INPROCEEDINGS{cnn_1,
  author={Uçkun, Fehmi Ayberk and Özer, Hakan and Nurbaş, Ekin and Onat, Emrah},
  booktitle={2020 28th Signal Processing and Communications Applications Conference (SIU)}, 
  title={Direction Finding Using Convolutional Neural Networks and Convolutional Recurrent Neural Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/SIU49456.2020.9302448}}

@INPROCEEDINGS{omr_ieee2_wang,
  author={Ju, Yunxia and Wang, Xichang and Chen, Xiangxi},
  booktitle={2019 11th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)}, 
  title={Research on OMR Recognition Based on Convolutional Neural Network Tensorflow Platform}, 
  year={2019},
  volume={},
  number={},
  pages={688-691},
  doi={10.1109/ICMTMA.2019.00157}}

@INPROCEEDINGS{omr_ieee3,
  author={Sarika, Naragudem and Sirisala, Nageswararao and Velpuru, Muni Sekhar},
  booktitle={2021 6th International Conference on Inventive Computation Technologies (ICICT)}, 
  title={CNN based Optical Character Recognition and Applications}, 
  year={2021},
  volume={},
  number={},
  pages={666-672},
  doi={10.1109/ICICT50816.2021.9358735}}

@INPROCEEDINGS{ResNeXt,
  author={Zhou, Tianyan and Zhao, Yong and Wu, Jian},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={ResNeXt and Res2Net Structures for Speaker Verification}, 
  year={2021},
  volume={},
  number={},
  pages={301-307},
  doi={10.1109/SLT48900.2021.9383531}}

@misc{zhang2017shufflenet,
      title={ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices}, 
      author={Xiangyu Zhang and Xinyu Zhou and Mengxiao Lin and Jian Sun},
      year={2017},
      eprint={1707.01083},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{shufflenet2,
  author={Gomes, Rahul and Rozario, Papia and Adhikari, Nishan},
  booktitle={2021 IEEE International Conference on Electro Information Technology (EIT)}, 
  title={Deep Learning optimization in remote sensing image segmentation using dilated convolutions and ShuffleNet}, 
  year={2021},
  volume={},
  number={},
  pages={244-249},
  doi={10.1109/EIT51626.2021.9491910}}

@misc{sklearn,
  author = {scikit-learn},
  year = {2023},
  title = {scikit-learn: Machine Learning in Python},
  url = {https://scikit-learn.org/stable/},
  urldate = {Nov 9, 2023}
}

@misc{tensorflow,
  author = {tensorflow},
  year = {2023},
  title = {Create production-grade machine learning models with TensorFlow},
  url = {https://www.tensorflow.org/},
  urldate = {Nov 9, 2023}
}

@misc{keras,
  author = {keras},
  year = {2023},
  title = {Keras: Deep Learning for humans},
  url = {https://keras.io/},
  urldate = {Nov 9, 2023}
}

@misc{torch,
  author = {PyTorch},
  year = {2023},
  title = {PyTorch: An open source machine learning framework that accelerates the path from research prototyping to production deploymen},
  url = {https://pytorch.org/},
  urldate = {Nov 9, 2023}
}

@misc{numpy,
  author = {NumPy},
  year = {2023},
  title = {NumPy},
  url = {https://numpy.org/},
  urldate = {Nov 9, 2023}
}

@misc{xgboost,
  author = {XGBoost},
  year = {2023},
  title = {XGBoost Documentation},
  url = {https://xgboost.readthedocs.io/en/stable/},
  urldate = {Nov 9, 2023}
}

@misc{pandas,
  author = {pandas},
  year = {2023},
  title = {pandas - Python Data Analysis Library},
  url = {https://pandas.pydata.org/},
  urldate = {Nov 9, 2023}
}

@misc{flask,
  author = {Flask},
  year = {2023},
  title = {Welcome to Flask — Flask Documentation (3.0.x)},
  url = {https://flask.palletsprojects.com/en/3.0.x/},
  urldate = {Nov 9, 2023}
}

@misc{vue,
  author = {Vue.js},
  year = {2023},
  title = {Vue.js - The Progressive JavaScript Framework},
  url = {https://vuejs.org/},
  urldate = {Nov 9, 2023}
}

@misc{pycharm,
  author = {jetbrains},
  year = {2023},
  title = {PyCharm: the Python IDE for Professional Developers},
  url = {https://www.jetbrains.com/pycharm/},
  urldate = {Nov 9, 2023}
}

@misc{jupyter,
  author = {Jupyter},
  year = {2023},
  title = {Jupyter Notebook},
  url = {https://jupyter.org/},
  urldate = {Nov 9, 2023}
}

@misc{colab,
  author = {Google Research},
  year = {2023},
  title = {Welcome To Colaboratory},
  url = {https://colab.research.google.com/},
  urldate = {Nov 9, 2023}
}

@misc{webstorm,
  author = {jetbrains},
  year = {2023},
  title = {WebStorm: The Smartest JavaScript IDE, by JetBrains},
  url = {https://www.jetbrains.com/webstorm/},
  urldate = {Nov 9, 2023}
}

@misc{roboflow,
  author = {RoboFlow},
  year = {2023},
  title = {Roboflow: Give your software the power to see objects},
  url = {https://roboflow.com/},
  urldate = {Nov 9, 2023}
}

@misc{ethic,
  author = {COMP390 Honours Year Project},
  year = {2023},
  title = {Ethical Guidance},
  url = {https://student.csc.liv.ac.uk/internal/modules/comp390/2023-24/ethics.php},
  urldate = {Nov 9, 2023}
}






@article{Meesad,
author = {Saengtongsrikamon, Chatree and Meesad, Phayung and Sodsee, Sunantha},
journal={Research Paper},
year = {2023},
month = {11},
pages = {},
title = {Scanner-Based Optical Mark Recognition}
}

@ARTICLE{Optical,
  author={Pérez-Benedito, José Luis and Aragón, Enrique Querol and Alriols, Juan Alonso and Medic, Ljiljana},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Optical Mark Recognition in Student Continuous Assessment}, 
  year={2014},
  volume={9},
  number={4},
  pages={133-138},
  doi={10.1109/RITA.2014.2363005}}

@INPROCEEDINGS{Scanner,
  author={Agarwal, Sparsh and Varun, Malempati and Prabakeran, S},
  booktitle={2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={OMR Reader Info Scanner}, 
  year={2023},
  volume={1},
  number={},
  pages={205-209},
  doi={10.1109/ICACCS57279.2023.10113018}}

@article{MOUSSA1991283,
title = {Analysis of multiple-choice items},
journal = {Computer Methods and Programs in Biomedicine},
volume = {34},
number = {4},
pages = {283-289},
year = {1991},
issn = {0169-2607},
doi = {https://doi.org/10.1016/0169-2607(91)90113-8},
url = {https://www.sciencedirect.com/science/article/pii/0169260791901138},
author = {M.A.A. Moussa and B.A. Ouda and A. Nemeth},
keywords = {Multiple choice questions, Difficulty index, Discrimination index, Optical mark reader}
}

@article{Zeki,
author = {Tümer, Abdullah and Küçükkara, Zeki},
year = {2018},
month = {12},
pages = {59-64},
title = {An Image Processing Oriented Optical Mark Recognition and Evaluation System},
volume = {6},
journal = {International Journal of Applied Mathematics, Electronics and Computers},
doi = {10.18100/ijamec.2018447788}
}






@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wightman2021resnet,
      title={ResNet strikes back: An improved training procedure in timm}, 
      author={Ross Wightman and Hugo Touvron and Hervé Jégou},
      year={2021},
      eprint={2110.00476},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zagoruyko2017wide,
      title={Wide Residual Networks}, 
      author={Sergey Zagoruyko and Nikos Komodakis},
      year={2017},
      eprint={1605.07146},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{githubGitHubDavda54sam,
	author = {},
	title = {{G}it{H}ub - davda54/sam: {S}{A}{M}: {S}harpness-{A}ware {M}inimization ({P}y{T}orch) --- github.com},
	howpublished = {\url{https://github.com/davda54/sam/tree/main}},
	year = {2022},
	note = {[Accessed 09-05-2024]},
}

@misc{foret2021sharpnessaware,
      title={Sharpness-Aware Minimization for Efficiently Improving Generalization}, 
      author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
      year={2021},
      eprint={2010.01412},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{pmlr-v162-andriushchenko22a,
  title = 	 {Towards Understanding Sharpness-Aware Minimization},
  author =       {Andriushchenko, Maksym and Flammarion, Nicolas},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {639--668},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/andriushchenko22a/andriushchenko22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/andriushchenko22a.html},
}

@incollection{bottou_stochastic_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Stochastic {Gradient} {Descent} {Tricks}},
	isbn = {978-3-642-35289-8},
	url = {https://doi.org/10.1007/978-3-642-35289-8_25},
	language = {en},
	urldate = {2022-03-19},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}: {Second} {Edition}},
	publisher = {Springer},
	author = {Bottou, Léon},
	editor = {Montavon, Grégoire and Orr, Geneviève B. and Müller, Klaus-Robert},
	year = {2012},
	doi = {10.1007/978-3-642-35289-8_25},
	keywords = {Conditional Random Field, Empirical Risk, Learning Rate, Stochastic Gradient, Support Vector Machine},
	pages = {421--436},
}





@misc{OpenCV_sheet,
	author = {Practical-CV},
	title = {Practical {CV}/{OMR} {S}canner and {T}est {G}rader {u}sing {O}pen{CV}},
	howpublished = {\url{https://github.com/Practical-CV/OMR-Scanner-and-Test-Grader-using-OpenCV}},
	year = {2022},
	note = {[Accessed 09-05-2024]},
}

@misc{pymupdf,
	author = {Artifex},
	title = {{P}y{M}u{P}{D}{F} 1.24.2 documentation --- pymupdf.readthedocs.io},
	howpublished = {\url{https://pymupdf.readthedocs.io/en/latest/}},
	year = {2024},
	note = {[Accessed 09-05-2024]},
}